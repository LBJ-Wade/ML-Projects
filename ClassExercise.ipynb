{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked-ensemble classifiers (in-class exercise)\n",
    "\n",
    "The idea is to build a stacked ensemble to make accurate predictions about tumor. \n",
    "\n",
    "The stacked ensemble works as follows\n",
    "\n",
    "- Level 0: the level zero classifiers predict, after training, the input data and generate the predicted output data.\n",
    "- Level 1: the level one classifier uses the predictions of the level zero classifiers as inputs and predict the output. This output is then compared to the true label to check accuracies and other performance metrics.\n",
    "\n",
    "\n",
    "For this exercise we will use the following classifiers:\n",
    "1. Support Vector Machine (SVM)\n",
    "2. Linear Discriminant Analysis (LDA)\n",
    "3. Quadratic Discriminant Analysis (QDA)\n",
    "4. Random Forest (RF)\n",
    "\n",
    "\n",
    "## 1. Loading the dataset\n",
    "Let us begin with loading and preprocessing the dataset.\n",
    "\n",
    "Here LabelEncoder() is very useful as it converts the classes (denoted here with the type of tumor (I guess)) from strings to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABHD2</th>\n",
       "      <th>ACTB</th>\n",
       "      <th>ACTR2</th>\n",
       "      <th>ACTR5</th>\n",
       "      <th>ACVR2A</th>\n",
       "      <th>ADAMDEC1</th>\n",
       "      <th>ADCYAP1R1</th>\n",
       "      <th>AEBP1</th>\n",
       "      <th>...</th>\n",
       "      <th>WT1</th>\n",
       "      <th>XPO7</th>\n",
       "      <th>XPOT</th>\n",
       "      <th>YTHDC2</th>\n",
       "      <th>ZDHHC14</th>\n",
       "      <th>ZDHHC7</th>\n",
       "      <th>ZEB1</th>\n",
       "      <th>ZFP36</th>\n",
       "      <th>ZHX3</th>\n",
       "      <th>ZNF423</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRO.C5</td>\n",
       "      <td>-0.010674</td>\n",
       "      <td>0.263376</td>\n",
       "      <td>-0.115492</td>\n",
       "      <td>-0.323565</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>-0.504271</td>\n",
       "      <td>-1.283720</td>\n",
       "      <td>-0.433908</td>\n",
       "      <td>0.673072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077048</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>-0.072049</td>\n",
       "      <td>0.243935</td>\n",
       "      <td>-0.056318</td>\n",
       "      <td>-0.204971</td>\n",
       "      <td>0.179639</td>\n",
       "      <td>-0.292136</td>\n",
       "      <td>-0.034261</td>\n",
       "      <td>0.490152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MES.C1</td>\n",
       "      <td>-0.710741</td>\n",
       "      <td>0.110421</td>\n",
       "      <td>0.532555</td>\n",
       "      <td>-0.253877</td>\n",
       "      <td>-0.389024</td>\n",
       "      <td>-0.121941</td>\n",
       "      <td>-1.732920</td>\n",
       "      <td>-0.727880</td>\n",
       "      <td>1.706110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547120</td>\n",
       "      <td>-0.674773</td>\n",
       "      <td>-0.236746</td>\n",
       "      <td>0.551354</td>\n",
       "      <td>0.215982</td>\n",
       "      <td>0.196677</td>\n",
       "      <td>1.467320</td>\n",
       "      <td>2.461040</td>\n",
       "      <td>0.415041</td>\n",
       "      <td>2.116880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIF.C4</td>\n",
       "      <td>0.881506</td>\n",
       "      <td>0.372862</td>\n",
       "      <td>0.052344</td>\n",
       "      <td>0.028721</td>\n",
       "      <td>-0.848119</td>\n",
       "      <td>-1.281180</td>\n",
       "      <td>1.524370</td>\n",
       "      <td>-0.288317</td>\n",
       "      <td>-2.010830</td>\n",
       "      <td>...</td>\n",
       "      <td>1.058170</td>\n",
       "      <td>0.350895</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.592285</td>\n",
       "      <td>-0.338954</td>\n",
       "      <td>-0.842242</td>\n",
       "      <td>0.096242</td>\n",
       "      <td>-0.471005</td>\n",
       "      <td>-1.662190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MES.C1</td>\n",
       "      <td>-1.085090</td>\n",
       "      <td>0.415651</td>\n",
       "      <td>0.395376</td>\n",
       "      <td>-0.271050</td>\n",
       "      <td>0.146536</td>\n",
       "      <td>-0.363270</td>\n",
       "      <td>0.993823</td>\n",
       "      <td>-0.450427</td>\n",
       "      <td>1.999170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.677226</td>\n",
       "      <td>-0.109778</td>\n",
       "      <td>0.033163</td>\n",
       "      <td>0.760080</td>\n",
       "      <td>-1.169030</td>\n",
       "      <td>0.325604</td>\n",
       "      <td>1.785760</td>\n",
       "      <td>-0.212328</td>\n",
       "      <td>0.537493</td>\n",
       "      <td>-0.102138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MES.C1</td>\n",
       "      <td>-0.932230</td>\n",
       "      <td>0.045352</td>\n",
       "      <td>0.595068</td>\n",
       "      <td>0.187856</td>\n",
       "      <td>-0.200287</td>\n",
       "      <td>0.211144</td>\n",
       "      <td>1.844640</td>\n",
       "      <td>-0.416482</td>\n",
       "      <td>1.327800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961688</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>0.529045</td>\n",
       "      <td>-0.551470</td>\n",
       "      <td>-0.188697</td>\n",
       "      <td>0.157393</td>\n",
       "      <td>0.469166</td>\n",
       "      <td>1.748000</td>\n",
       "      <td>0.144196</td>\n",
       "      <td>-0.561641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    class      ABAT     ABHD2      ACTB     ACTR2     ACTR5    ACVR2A  \\\n",
       "0  PRO.C5 -0.010674  0.263376 -0.115492 -0.323565  0.005161 -0.504271   \n",
       "1  MES.C1 -0.710741  0.110421  0.532555 -0.253877 -0.389024 -0.121941   \n",
       "2  DIF.C4  0.881506  0.372862  0.052344  0.028721 -0.848119 -1.281180   \n",
       "3  MES.C1 -1.085090  0.415651  0.395376 -0.271050  0.146536 -0.363270   \n",
       "4  MES.C1 -0.932230  0.045352  0.595068  0.187856 -0.200287  0.211144   \n",
       "\n",
       "   ADAMDEC1  ADCYAP1R1     AEBP1    ...          WT1      XPO7      XPOT  \\\n",
       "0 -1.283720  -0.433908  0.673072    ...     0.077048  0.459961 -0.072049   \n",
       "1 -1.732920  -0.727880  1.706110    ...     0.547120 -0.674773 -0.236746   \n",
       "2  1.524370  -0.288317 -2.010830    ...     1.058170  0.350895 -0.000051   \n",
       "3  0.993823  -0.450427  1.999170    ...    -0.677226 -0.109778  0.033163   \n",
       "4  1.844640  -0.416482  1.327800    ...     0.961688 -0.009010  0.529045   \n",
       "\n",
       "     YTHDC2   ZDHHC14    ZDHHC7      ZEB1     ZFP36      ZHX3    ZNF423  \n",
       "0  0.243935 -0.056318 -0.204971  0.179639 -0.292136 -0.034261  0.490152  \n",
       "1  0.551354  0.215982  0.196677  1.467320  2.461040  0.415041  2.116880  \n",
       "2  0.010498  0.592285 -0.338954 -0.842242  0.096242 -0.471005 -1.662190  \n",
       "3  0.760080 -1.169030  0.325604  1.785760 -0.212328  0.537493 -0.102138  \n",
       "4 -0.551470 -0.188697  0.157393  0.469166  1.748000  0.144196 -0.561641  \n",
       "\n",
       "[5 rows x 322 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read the dataset\n",
    "dt = pd.read_csv('hgsc.csv')\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt=dt.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now x, y\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "X = dt.loc[:,dt.columns!='class']\n",
    "#dt['class']=dt['class'].astype('integer') # the following is useless.. We can use LabelEncoder from sklearn.preprocessing\n",
    "y = dt['class']\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489, 321)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape of the predictors.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now split in test and train set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.01982714e-01,   9.80500683e-02,   4.50952245e-02,\n",
       "         3.28677337e-02,   2.71819534e-02,   2.63146339e-02,\n",
       "         2.32510173e-02,   2.04708606e-02,   1.78945311e-02,\n",
       "         1.70066134e-02,   1.60041367e-02,   1.41087792e-02,\n",
       "         1.37462630e-02,   1.27609644e-02,   1.17572668e-02,\n",
       "         1.15436857e-02,   1.10070860e-02,   1.04476933e-02,\n",
       "         9.93750956e-03,   9.75405495e-03,   9.26826009e-03,\n",
       "         8.97313656e-03,   8.35131226e-03,   8.31322249e-03,\n",
       "         8.15083584e-03,   7.74742475e-03,   7.48789495e-03,\n",
       "         7.17772807e-03,   7.00037755e-03,   6.83781926e-03,\n",
       "         6.48984306e-03,   6.30554819e-03,   5.97381484e-03,\n",
       "         5.85819461e-03,   5.67160016e-03,   5.45704134e-03,\n",
       "         5.35321359e-03,   5.21310330e-03,   5.07535720e-03,\n",
       "         4.97845240e-03,   4.66597872e-03,   4.65741960e-03,\n",
       "         4.54072631e-03,   4.52548451e-03,   4.43649612e-03,\n",
       "         4.33814835e-03,   4.20124994e-03,   4.12575416e-03,\n",
       "         4.11653871e-03,   3.95379453e-03,   3.92452174e-03,\n",
       "         3.81891697e-03,   3.67982223e-03,   3.66774917e-03,\n",
       "         3.59566651e-03,   3.50928975e-03,   3.46695691e-03,\n",
       "         3.42770786e-03,   3.30112411e-03,   3.24727345e-03,\n",
       "         3.15290187e-03,   3.05846005e-03,   2.97347018e-03,\n",
       "         2.91183849e-03,   2.83378583e-03,   2.81495316e-03,\n",
       "         2.76407795e-03,   2.74605499e-03,   2.67849105e-03,\n",
       "         2.65553665e-03,   2.64998439e-03,   2.54085073e-03,\n",
       "         2.50162717e-03,   2.43972325e-03,   2.35309275e-03,\n",
       "         2.32119536e-03,   2.21834476e-03,   2.21434289e-03,\n",
       "         2.18841012e-03,   2.12867134e-03,   2.08062762e-03,\n",
       "         2.06553040e-03,   2.03546500e-03,   1.97090723e-03,\n",
       "         1.95333821e-03,   1.91492115e-03,   1.87171688e-03,\n",
       "         1.83600541e-03,   1.79202587e-03,   1.75104806e-03,\n",
       "         1.71989980e-03,   1.70631299e-03,   1.66802291e-03,\n",
       "         1.64246912e-03,   1.61735172e-03,   1.59911026e-03,\n",
       "         1.55483539e-03,   1.49256746e-03,   1.47228296e-03,\n",
       "         1.46329056e-03,   1.44959692e-03,   1.42378602e-03,\n",
       "         1.39700983e-03,   1.33946918e-03,   1.31340676e-03,\n",
       "         1.30318004e-03,   1.28310635e-03,   1.25265885e-03,\n",
       "         1.24706306e-03,   1.22272702e-03,   1.19878480e-03,\n",
       "         1.17328684e-03,   1.16107167e-03,   1.13380382e-03,\n",
       "         1.12545251e-03,   1.11584892e-03,   1.09891758e-03,\n",
       "         1.08376824e-03,   1.05910120e-03,   1.03734187e-03,\n",
       "         9.90914264e-04,   9.86329362e-04,   9.57316793e-04,\n",
       "         9.54127798e-04,   9.18643457e-04,   9.14682170e-04,\n",
       "         8.88731788e-04,   8.84080640e-04,   8.60672780e-04,\n",
       "         8.48713862e-04,   8.17755452e-04,   8.15567092e-04,\n",
       "         7.76395980e-04,   7.65042823e-04,   7.49668838e-04,\n",
       "         7.41297486e-04,   7.30183582e-04,   7.20973332e-04,\n",
       "         7.06616342e-04,   6.94775849e-04,   6.68463547e-04,\n",
       "         6.54126431e-04,   6.42544954e-04,   6.22796995e-04,\n",
       "         6.14397873e-04,   6.03235890e-04,   5.95344375e-04,\n",
       "         5.89470818e-04,   5.66909998e-04,   5.57760748e-04,\n",
       "         5.40765572e-04,   5.28206744e-04,   5.19116145e-04,\n",
       "         5.05045101e-04,   5.02702512e-04,   4.93009658e-04,\n",
       "         4.85314132e-04,   4.71177065e-04,   4.57507803e-04,\n",
       "         4.52743903e-04,   4.43666772e-04,   4.32475134e-04,\n",
       "         4.20173596e-04,   4.12697162e-04,   4.02444443e-04,\n",
       "         3.94416688e-04,   3.86993397e-04,   3.86471556e-04,\n",
       "         3.65615601e-04,   3.58379123e-04,   3.54618250e-04,\n",
       "         3.48340980e-04,   3.38356620e-04,   3.30568919e-04,\n",
       "         3.21346537e-04,   3.04687155e-04,   2.95316570e-04,\n",
       "         2.94756956e-04,   2.85351487e-04,   2.75402244e-04,\n",
       "         2.65585939e-04,   2.60787976e-04,   2.56437576e-04,\n",
       "         2.53609094e-04,   2.43511760e-04,   2.39743723e-04,\n",
       "         2.27352793e-04,   2.23839099e-04,   2.09670686e-04,\n",
       "         2.03606083e-04,   2.00443602e-04,   1.94940750e-04,\n",
       "         1.88786353e-04,   1.79999959e-04,   1.78177801e-04,\n",
       "         1.68164026e-04,   1.60807526e-04,   1.58346094e-04,\n",
       "         1.56198231e-04,   1.49880852e-04,   1.48920159e-04,\n",
       "         1.43902417e-04,   1.40334788e-04,   1.33258961e-04,\n",
       "         1.30910682e-04,   1.22692675e-04,   1.21739611e-04,\n",
       "         1.18505160e-04,   1.16618243e-04,   1.08067654e-04,\n",
       "         1.07626992e-04,   1.03295124e-04,   9.59280180e-05,\n",
       "         9.41754060e-05,   8.95420034e-05,   8.56004181e-05,\n",
       "         8.36501531e-05,   7.99310521e-05,   7.56791802e-05,\n",
       "         7.41913581e-05,   7.02653467e-05,   6.48623600e-05,\n",
       "         6.34542311e-05,   6.03687845e-05,   5.74630252e-05,\n",
       "         5.33595261e-05,   5.19980854e-05,   4.72625409e-05,\n",
       "         4.50686321e-05,   4.45756070e-05,   4.31960955e-05,\n",
       "         3.75666178e-05,   3.58097523e-05,   3.49775392e-05,\n",
       "         3.27349771e-05,   3.00214376e-05,   2.81440750e-05,\n",
       "         2.61338860e-05,   2.41726253e-05,   1.97419075e-05,\n",
       "         1.82118294e-05,   1.65384892e-05,   1.38898718e-05,\n",
       "         3.98340667e-32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the PCA.. it might be useful for LDA and QDA (their accuracy is terrible..)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_std=sc.fit_transform(X_train)\n",
    "pca = PCA(n_components = None)\n",
    "pca.fit(X_train_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tuning the single classifiers\n",
    "\n",
    "### 2.1 Tuning a SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8934426229508197\n",
      "{'clf__C': 0.01, 'clf__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "pipe_svc = Pipeline([('scl', StandardScaler()),\n",
    "            ('clf', SVC(random_state=1, probability=True))])\n",
    "\n",
    "\n",
    "# This stuff is to choose the best paramters of the \n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'clf__C': param_range, \n",
    "               'clf__kernel': ['linear']},\n",
    "                 {'clf__C': param_range, \n",
    "                  'clf__gamma': param_range, \n",
    "                  'clf__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svc, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, so the best SVM for this problem seems to be a linear svm with C=0.01. So we'll use that in our stacked ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.865306122449\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "gs.best_estimator_.fit(X_train, y_train)\n",
    "print(gs.best_estimator_.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM confmat:\n",
      " [[67  2  3  2]\n",
      " [ 4 45  2  0]\n",
      " [ 4  2 48  1]\n",
      " [ 6  4  3 52]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_best = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "confmat = confusion_matrix(y_true = y_test, y_pred=y_pred_best)\n",
    "print('SVM confmat:\\n',confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Linear Discriminant Analysis\n",
    "Moving with the Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipe_lda_accuracy: 0.563265306122\n",
      "lda_accuracy: 0.563265306122\n",
      "pipe lda confmat:\n",
      " [[45  9 14  6]\n",
      " [15 21  8  7]\n",
      " [10  4 38  3]\n",
      " [15 11  5 34]]\n",
      "lda confmat: \n",
      " [[45  9 14  6]\n",
      " [15 21  8  7]\n",
      " [10  4 38  3]\n",
      " [15 11  5 34]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexzucca/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Now define a LDA pipeline.\n",
    "#from sklearn.lda import LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "pipe_lda = Pipeline([('sc', StandardScaler()),\n",
    "                    ('clf', LDA())])\n",
    "\n",
    "lda = LDA()\n",
    "\n",
    "pipe_lda.fit(X_train, y_train)\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "print('pipe_lda_accuracy:',pipe_lda.score(X_test, y_test))\n",
    "print('lda_accuracy:',lda.score(X_test, y_test))\n",
    "\n",
    "y_pred_pipe = pipe_lda.predict(X_test)\n",
    "confmat=  confusion_matrix(y_true = y_test, y_pred=y_pred_pipe)\n",
    "print('pipe lda confmat:\\n',confmat)\n",
    "\n",
    "y_pred = lda.predict(X_test)\n",
    "confmat=  confusion_matrix(y_true = y_test, y_pred=y_pred)\n",
    "print('lda confmat: \\n',confmat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear discriminant analysis seems a very weak classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexzucca/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.338775510204\n",
      "0.387755102041\n"
     ]
    }
   ],
   "source": [
    "# Next define the QDA pipeline\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "pipe_qda = Pipeline([('sc', StandardScaler()),\n",
    "                    ('clf', QDA())])\n",
    "qda = QDA()\n",
    "\n",
    "pipe_qda.fit(X_train, y_train)\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "print(pipe_qda.score(X_test, y_test))\n",
    "print(qda.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA confmat: \n",
      " [[20 26 11 17]\n",
      " [10 23  9  9]\n",
      " [15 17 16  7]\n",
      " [11 11  7 36]]\n"
     ]
    }
   ],
   "source": [
    "# I definitely choose the non standardize case. Now computing the confusion matrix\n",
    "y_pred = qda.predict(X_test)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print('QDA confmat: \\n', confmat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QDA is even weaker than the LDA. Not sure why.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Random Forest\n",
    "Here I should tune up the parameters of the random forest classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 0.840816326531\n",
      "Pipe Random Forest Accuracy 0.840816326531\n"
     ]
    }
   ],
   "source": [
    "# Last, let's define the Random Forest Pipeline\n",
    "\n",
    "from  sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "pipe_rf = Pipeline([('sc', StandardScaler()),\n",
    "                    ('clf', RandomForestClassifier(criterion='gini',random_state=1,n_jobs=4))])\n",
    "\n",
    "rf = RandomForestClassifier(criterion='gini', \n",
    "                                random_state=1,\n",
    "                                n_jobs=4)\n",
    "\n",
    "# Actually I want to understand what's going on with this thing, so let's try the following.\n",
    "rf.fit(X_train, y_train)\n",
    "rf_acc = rf.score(X_test, y_test)\n",
    "print('Random Forest accuracy:',rf_acc)\n",
    "\n",
    "pipe_rf.fit(X_train,y_train)\n",
    "pipe_rf_acc = pipe_rf.score(X_test,y_test)\n",
    "print('Pipe Random Forest Accuracy', pipe_rf_acc)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF confmat:\n",
      " [[55  3  6 10]\n",
      " [ 2 46  3  0]\n",
      " [ 3  2 49  1]\n",
      " [ 5  2  2 56]]\n"
     ]
    }
   ],
   "source": [
    "# no difference, let's keep the random forest with no normalization\n",
    "y_pred = rf.predict(X_test)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print('RF confmat:\\n', confmat )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stacked Ensemble.\n",
    "### 3.1. First trial: there is no J-folding here\n",
    "The following code suffers (for sure) of overfitting. But it's a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying to code the stacked ensemble classifier\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class StackedEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, lev0_clfs, lev1_clf, J ,weights = None):\n",
    "        self.lev0_clfs = lev0_clfs\n",
    "        self.named_clfs = {key: value for key, value in _name_estimators(lev0_clfs)}\n",
    "        self.lev1_clf = lev1_clf\n",
    "        self.weights = weights\n",
    "        # number of folds\n",
    "        self.J = J\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "                \n",
    "        # lev0_clfs_ is the set of fitted classifiers.\n",
    "        self.lev0_clfs_ = []\n",
    "        \n",
    "        # Now fit each classifier\n",
    "        for clf in self.lev0_clfs:\n",
    "            fitted_clf = clf.fit(X,y)\n",
    "            self.lev0_clfs_.append(fitted_clf)\n",
    "        \n",
    "        # Initialize the array for the level 1 classifier\n",
    "        rows = X.shape[0]\n",
    "        columns = len(np.unique(y))*len(self.lev0_clfs)\n",
    "        \n",
    "        self.num_classes = len(np.unique(y))\n",
    "        \n",
    "        X2=np.zeros((rows, columns))\n",
    "        \n",
    "        # Prepare the data for the level 1 classifier\n",
    "        for i in range(len(self.lev0_clfs_)):\n",
    "            clf = self.lev0_clfs_[i]\n",
    "            X_temp=clf.predict_proba(X)\n",
    "            for j in range(X_temp.shape[1]):\n",
    "                for k in range(X2.shape[0]):\n",
    "                    c = len(np.unique(y))*i+j\n",
    "                    X2[k][c] = X_temp[k][j]\n",
    "        \n",
    "        \n",
    "        # now train the level 1 classifier\n",
    "        self.lev1_clf_ = self.lev1_clf.fit(X2,y)\n",
    "        \n",
    "        # That's it        \n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \n",
    "        rows = X.shape[0]\n",
    "        columns = self.num_classes*len(self.lev0_clfs_)\n",
    "    \n",
    "        X2=np.zeros((rows, columns))\n",
    "        print('X2.shape:',X2.shape)\n",
    "        \n",
    "        for i in range(len(self.lev0_clfs_)):\n",
    "            clf = self.lev0_clfs_[i]\n",
    "            X_temp=clf.predict_proba(X)\n",
    "            for j in range(X_temp.shape[1]):\n",
    "                for k in range(X2.shape[0]):\n",
    "                    c = len(np.unique(y))*i+j\n",
    "                    #print(k,c)\n",
    "                    X2[k][c] = X_temp[k][j]\n",
    "                    \n",
    "                    \n",
    "        # now feed this stuff into the lev1_classifier\n",
    "        y_pred = self.lev1_clf_.predict(X2)\n",
    "        return(y_pred)\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        # will modify this later.\n",
    "        \n",
    "        rows = X.shape[0]\n",
    "        columns = self.num_classes*len(self.lev0_clfs_)\n",
    "    \n",
    "        X2=np.zeros((rows, columns))\n",
    "        print('X2.shape:',X2.shape)\n",
    "        \n",
    "        for i in range(len(self.lev0_clfs_)):\n",
    "            clf = self.lev0_clfs_[i]\n",
    "            X_temp=clf.predict_proba(X)\n",
    "            for j in range(X_temp.shape[1]):\n",
    "                for k in range(X2.shape[0]):\n",
    "                    c = len(np.unique(y))*i+j\n",
    "                    #print(k,c)\n",
    "                    X2[k][c] = X_temp[k][j]\n",
    "                    \n",
    "                    \n",
    "        # now feed this stuff into the lev1_classifier\n",
    "        \n",
    "        p_pred = self.lev1_clf_.predict_proba(X)\n",
    "        \n",
    "        return(p_pred)\n",
    "    \n",
    "        # return prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Now combining the stuff..\n",
    "\n",
    "# this is going to be the level-1 classifier\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# these are the level-0 classifiers.\n",
    "#getting the best estimator from sect. 2.1\n",
    "svc = gs.best_estimator_\n",
    "rf = RandomForestClassifier()\n",
    "lda = LDA()\n",
    "qda=QDA()\n",
    "\n",
    "\n",
    "sec=StackedEnsembleClassifier([svc,rf,lda,qda], lr, J=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now try to fit the thing\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_std = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexzucca/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/alexzucca/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackedEnsembleClassifier(J=2,\n",
       "             lev0_clfs=[Pipeline(memory=None,\n",
       "     steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=1,...ors=None, reg_param=0.0,\n",
       "               store_covariance=False, store_covariances=None, tol=0.0001)],\n",
       "             lev1_clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "             weights=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now train the ensemble.\n",
    "sec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2.shape: (245, 16)\n"
     ]
    }
   ],
   "source": [
    "y_pred = sec.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = 1.0 - (y_pred != y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Stacked Ensemble: 0.771428571429\n"
     ]
    }
   ],
   "source": [
    "print('accuracy Stacked Ensemble:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now I want to compute the confusion matrix here\n",
    "confmat = confusion_matrix(y_true = y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Ensemble confmat:\n",
      " [[55 10  3  6]\n",
      " [ 7 37  5  2]\n",
      " [ 5  4 44  2]\n",
      " [ 6  4  2 53]]\n"
     ]
    }
   ],
   "source": [
    "print('Stacked Ensemble confmat:\\n', confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2.shape: (245, 12)\n",
      "accuracy Stacked Ensemble: 0.767346938776\n",
      "Stacked Ensemble confmat:\n",
      " [[55  7  7  5]\n",
      " [ 9 35  7  0]\n",
      " [ 4  2 47  2]\n",
      " [ 7  4  3 51]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexzucca/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# The issue might come from the QDA. Let's avoid it\n",
    "sec=StackedEnsembleClassifier([svc,rf, lda], lr, J=2)\n",
    "sec.fit(X_train, y_train)\n",
    "y_pred = sec.predict(X_test)\n",
    "accuracy = 1.0 - (y_pred != y_test).sum()/len(y_test)\n",
    "print('accuracy Stacked Ensemble:', accuracy)\n",
    "confmat = confusion_matrix(y_true = y_test, y_pred=y_pred)\n",
    "print('Stacked Ensemble confmat:\\n', confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we're not good enough. Let's see what happens if we get rid of the lda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2.shape: (245, 8)\n",
      "accuracy Stacked Ensemble: 0.902040816327\n",
      "Stacked Ensemble confmat:\n",
      " [[67  0  3  4]\n",
      " [ 1 48  2  0]\n",
      " [ 5  1 49  0]\n",
      " [ 4  2  2 57]]\n"
     ]
    }
   ],
   "source": [
    "# The issue might come from the QDA. Let's avoid it\n",
    "sec=StackedEnsembleClassifier([svc,rf], lr, J=2)\n",
    "sec.fit(X_train, y_train)\n",
    "y_pred = sec.predict(X_test)\n",
    "accuracy = 1.0 - (y_pred != y_test).sum()/len(y_test)\n",
    "print('accuracy Stacked Ensemble:', accuracy)\n",
    "confmat = confusion_matrix(y_true = y_test, y_pred=y_pred)\n",
    "print('Stacked Ensemble confmat:\\n', confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works better. Good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Implementing J-foldings here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying to code the stacked ensemble classifier\n",
    "\n",
    "# Before implementing the actual J-fold methid, I want to train and predict on the same thing... just to practice.\n",
    "\n",
    "# Now J-folding\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class StackedEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, lev0_clfs, lev1_clf, J ,weights = None):\n",
    "        self.lev0_clfs = lev0_clfs\n",
    "        self.named_clfs = {key: value for key, value in _name_estimators(lev0_clfs)}\n",
    "        self.lev1_clf = lev1_clf\n",
    "        self.weights = weights\n",
    "        # number of folds\n",
    "        self.J = J\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # Initialize the k-fold\n",
    "        \n",
    "        # Initialize the Kfold stuff\n",
    "        #kf = KFold(n_splits = self.J, random_state=42)\n",
    "        \n",
    "        # lev0_clfs_ is the set of fitted classifiers.\n",
    "        self.lev0_clfs_ = []\n",
    "        \n",
    "        # Now fit each classifier\n",
    "        for clf in self.lev0_clfs:\n",
    "            fitted_clf = clf.fit(X,y)\n",
    "            self.lev0_clfs_.append(fitted_clf)\n",
    "            \n",
    "        #print('classifiers fitted..')\n",
    "        \n",
    "        \n",
    "        # Initialize the array for the level 1 classifier\n",
    "        rows = X.shape[0]\n",
    "        columns = len(np.unique(y))*len(self.lev0_clfs)\n",
    "        \n",
    "        self.num_classes = len(np.unique(y))\n",
    "        \n",
    "        X2=np.zeros((rows, columns))\n",
    "        #print('X2.shape:',X2.shape)\n",
    "\n",
    "\n",
    "        #first_iter = True\n",
    "        #ind=0\n",
    "        #for (train, test) in kf.split(X, y):\n",
    "        #    #print('k:',k)\n",
    "        #    ind+=1\n",
    "        #    print('ind:', ind)\n",
    "\n",
    "            # Initialize a temporary array\n",
    "        #    rows_temp = len(y[test])\n",
    "        #    X_temp = np.zeros((rows_temp, columns))\n",
    "        #    \n",
    "            # level 0 for the k-th fold\n",
    "        #    for i in range(len(self.lev0_clfs)):\n",
    "        #        self.lev0_clfs[i].fit(X[train], y[train])\n",
    "        #        X_temp2 = self.lev0_clfs[i].predict_proba(X[test])\n",
    "                \n",
    "        #        for n in range(X_temp.shape[0]):\n",
    "        #            for m in range(X_temp2.shape[1]):\n",
    "        #                c = len(np.unique(y))*i+m\n",
    "        #                X_temp[n][c] = X_temp2[n][m]\n",
    "        #                \n",
    "        #    if (first_iter):\n",
    "        #        X2 = X_temp\n",
    "        #        first_iter = False\n",
    "        #    else:\n",
    "        #        X2 = np.concatenate((X2,X_temp))\n",
    "              \n",
    "            \n",
    "        #print('X2.shape:', X2.shape)\n",
    "                \n",
    "                        \n",
    "        \n",
    "        \n",
    "        for i in range(len(self.lev0_clfs_)):\n",
    "            clf = self.lev0_clfs_[i]\n",
    "            X_temp=clf.predict_proba(X)\n",
    "            for j in range(X_temp.shape[1]):\n",
    "                for k in range(X2.shape[0]):\n",
    "                    c = len(np.unique(y))*i+j\n",
    "        #            #print(k,c)\n",
    "                    X2[k][c] = X_temp[k][j]\n",
    "        \n",
    "        \n",
    "        # now train the level 1 classifier\n",
    "        self.lev1_clf_ = self.lev1_clf.fit(X2,y)\n",
    "        \n",
    "        # That's it        \n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \n",
    "        rows = X.shape[0]\n",
    "        columns = self.num_classes*len(self.lev0_clfs_)\n",
    "    \n",
    "        X2=np.zeros((rows, columns))\n",
    "        print('X2.shape:',X2.shape)\n",
    "        \n",
    "        for i in range(len(self.lev0_clfs_)):\n",
    "            clf = self.lev0_clfs_[i]\n",
    "            X_temp=clf.predict_proba(X)\n",
    "            for j in range(X_temp.shape[1]):\n",
    "                for k in range(X2.shape[0]):\n",
    "                    c = len(np.unique(y))*i+j\n",
    "                    #print(k,c)\n",
    "                    X2[k][c] = X_temp[k][j]\n",
    "                    \n",
    "                    \n",
    "        # now feed this stuff into the lev1_classifier\n",
    "        y_pred = self.lev1_clf_.predict(X2)\n",
    "        return(y_pred)\n",
    "        # return prediction\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        # will modify this later.\n",
    "        \n",
    "        rows = X.shape[0]\n",
    "        columns = self.num_classes*len(self.lev0_clfs_)\n",
    "    \n",
    "        X2=np.zeros((rows, columns))\n",
    "        print('X2.shape:',X2.shape)\n",
    "        \n",
    "        for i in range(len(self.lev0_clfs_)):\n",
    "            clf = self.lev0_clfs_[i]\n",
    "            X_temp=clf.predict_proba(X)\n",
    "            for j in range(X_temp.shape[1]):\n",
    "                for k in range(X2.shape[0]):\n",
    "                    c = len(np.unique(y))*i+j\n",
    "                    #print(k,c)\n",
    "                    X2[k][c] = X_temp[k][j]\n",
    "                    \n",
    "                    \n",
    "        # now feed this stuff into the lev1_classifier\n",
    "        \n",
    "        p_pred = self.lev1_clf_.predict_proba(X)\n",
    "        \n",
    "        return(p_pred)\n",
    "    \n",
    "        # return prediction probabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
